{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR for CPI prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, lag):\n",
    "    \"\"\"Preprocesses the CPI data by removing unwanted columns, handling missing values, creating lag features, \n",
    "    and scaling the features. Additionally, returns the scaler used for future data transformation.\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The CPI data.\n",
    "        lag (int): The number of months to lag in the feature creation.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: The preprocessed and feature-engineered data.\n",
    "        StandardScaler: The scaler used for feature scaling.\n",
    "    \"\"\"\n",
    "    # Remove unwanted columns\n",
    "    data.drop('12 Month MA / Current Inflation', axis=1, inplace=True)\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    # Create a lagged CPI feature\n",
    "    column_name = f'CPI {lag} Month{\"s\" if lag > 1 else \"\"} ahead'\n",
    "    data[column_name] = data['CPI'].shift(-lag)\n",
    "    \n",
    "    # Remove the 'Year and Month' column\n",
    "    data.drop('Year and Month', axis=1, inplace=True)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    data.iloc[:, :-1] = scaler.fit_transform(data.iloc[:, :-1])\n",
    "    \n",
    "    return data, scaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Monthly_data.csv')\n",
    "\n",
    "#Lag - how many months ahead we want to predict\n",
    "lag = 3\n",
    "\n",
    "# Preprocess the data and save the scaler for later use\n",
    "data_processed, scaler = preprocess_data(data, lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error (MSE): 0.04759297366944496\n",
      "Test Mean Squared Error (MSE): 0.2166349882897096\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_processed.iloc[:-lag, :-1], data_processed.iloc[:-lag, -1], test_size=0.2)\n",
    "\n",
    "# Initialize the SVR model with specific parameters\n",
    "model = SVR(C=20, epsilon=0.05)\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the CPI values for the training dataset\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Predict the CPI values for the test dataset\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) for the training dataset\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train Mean Squared Error (MSE):\", mse_train)\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) for the test dataset\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"Test Mean Squared Error (MSE):\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to accumulate MSEs\n",
    "total_mse_train = 0\n",
    "total_mse_test = 0\n",
    "\n",
    "# Number of Monte Carlo simulations\n",
    "n_simulations = 1000\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    # Split the data into training and testing sets randomly\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_processed.iloc[:-lag, :-1], data_processed.iloc[:-lag, -1], test_size=0.2)\n",
    "    \n",
    "    # Initialize and train the SVR model\n",
    "    model = SVR(C=20, epsilon=0.05)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE for the current split\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Accumulate MSEs\n",
    "    total_mse_train += mse_train\n",
    "    total_mse_test += mse_test\n",
    "\n",
    "# Calculate the average MSE over all simulations\n",
    "average_mse_train = total_mse_train / n_simulations\n",
    "average_mse_test = total_mse_test / n_simulations\n",
    "\n",
    "print(\"Average Train Mean Squared Error (MSE):\", average_mse_train)\n",
    "print(\"Average Test Mean Squared Error (MSE):\", average_mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds and repeats\n",
    "n_folds = 10\n",
    "n_repeats = 500  \n",
    "\n",
    "# Creating the SVR model\n",
    "svr_model = SVR(C=20, epsilon=0.05)\n",
    "\n",
    "# Preparing the data\n",
    "X = data_processed.iloc[:-lag, :-1]  # input features\n",
    "y = data_processed.iloc[:-lag, -1]   # target variable\n",
    "\n",
    "# Creating a RepeatedKFold object\n",
    "rkf = RepeatedKFold(n_splits=n_folds, n_repeats=n_repeats)\n",
    "\n",
    "# Calculating cross-validation scores using neg_mean_squared_error to maximize the score\n",
    "cv_scores = cross_val_score(svr_model, X, y, cv=rkf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Converting scores to positive MSE values\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculating the average MSE and the 10th and 90th percentiles\n",
    "average_mse = np.mean(mse_scores)\n",
    "percentile_10 = np.percentile(mse_scores, 10)\n",
    "percentile_90 = np.percentile(mse_scores, 90)\n",
    "\n",
    "print(f\"Average MSE: {average_mse:.4f}\")\n",
    "print(f\"10th Percentile of MSE: {percentile_10:.4f}\")\n",
    "print(f\"90th Percentile of MSE: {percentile_90:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test Errors for Different C Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_processed.iloc[:-lag, :-1], data_processed.iloc[:-lag, -1], test_size=0.2)\n",
    "\n",
    "# Range of C values\n",
    "C_values = np.linspace(1, 50, 100)\n",
    "\n",
    "# Initialize lists to store the errors\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Loop over the range of C values\n",
    "for C in C_values:\n",
    "    model = SVR(C=C, epsilon=0.05)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate MSE for training and testing sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_errors.append(mean_squared_error(y_train, y_train_pred))\n",
    "    test_errors.append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(C_values, train_errors, label='Train Error')\n",
    "plt.plot(C_values, test_errors, label='Test Error')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Train and Test MSE for Different C Values in SVR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test errors for different C and epsilon values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_processed.iloc[:-lag, :-1], data_processed.iloc[:-lag, -1], test_size=0.2)\n",
    "\n",
    "# Define ranges for C and epsilon\n",
    "C_range = np.linspace(1, 50, 10)\n",
    "epsilon_range = np.linspace(0.01, 0.5, 10)\n",
    "test_errors = np.zeros((len(C_range), len(epsilon_range)))\n",
    "\n",
    "# Loop over the ranges of C and epsilon to train models and record the test error\n",
    "for i, C in enumerate(C_range):\n",
    "    for j, epsilon in enumerate(epsilon_range):\n",
    "        model = SVR(C=C, epsilon=epsilon)\n",
    "        model.fit(X_train, y_train)  # Using X_train without scaling as per your instruction\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_errors[i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Generate the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(test_errors, xticklabels=np.round(epsilon_range, 2), yticklabels=np.round(C_range, 2), annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Test MSE for Different Levels of C and Epsilon in SVR')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.90016639 1.55525751 1.90747421].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     13\u001b[0m predicted_cpi \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(prediction_data)\n\u001b[1;32m---> 15\u001b[0m predicted_cpi_inverse \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predicted_cpi)\n\u001b[0;32m     17\u001b[0m predicted_cpi_inverse\n",
      "File \u001b[1;32mc:\\Users\\giolu\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1046\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1043\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1045\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1046\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1047\u001b[0m     X,\n\u001b[0;32m   1048\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1049\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1050\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1051\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1052\u001b[0m )\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\giolu\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.90016639 1.55525751 1.90747421].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "prediction_data = data_processed.iloc[-lag:, :-1]\n",
    "\n",
    "# Initialize the SVR model with specific parameters\n",
    "model = SVR(C=20, epsilon=0.05)\n",
    "\n",
    "# Preparing the data\n",
    "X = data_processed.iloc[:-lag, :-1]  # input features\n",
    "y = data_processed.iloc[:-lag, -1]   # target variable\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "predicted_cpi = model.predict(prediction_data)\n",
    "\n",
    "predicted_cpi_inverse = scaler.inverse_transform(predicted_cpi)\n",
    "\n",
    "predicted_cpi_inverse\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
